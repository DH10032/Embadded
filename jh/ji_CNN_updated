





import torch                                                    # 기본 import(텐서와 텐서 계산 라이브러리)
from torch.utils.data import Dataset, DataLoader, random_split  # DataLoader 등 함수를 위한 import
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from pathlib import Path
import random

# ===========================================================================

# 경로 설정
path = Path('/home/jijijiho/다운로드/한국어글자체/syllables')  # 손글씨와 프린트 글씨가 있는 경로

# 하이퍼파라미터 설정
learning_rate = 0.00005     # backword 과정에서 SGD를 할 때 중요하게 쓰임
num_epoch = 30              # 전체 데이터셋을 학습 하는 횟수
new_width = 200             # 이미지 사이즈 통일 아래 cnn 계산할 때를 위함
new_height = 200            # 이미지 사이즈 통일 아래 cnn 계산할 때를 위함
Num_Img = 2000              # 랜덤으로 가져오는 이미지 개수
batch_size = 32             # 배치 크기 설정 (한 번의 훈련에 사용되는 샘플 수)

# ===========================================================================

# 디바이스 설정
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")       # 만약 현재 장치가 GPU를 지원하지 못한다면, CPU를 Device로 지정
print(DEVICE)

# 데이터셋 클래스 정의
class DL(Dataset):
    def __init__(self, path, num_img):
        self.path = path
        self.num_img = num_img
        self.data = self.load_data()
    
    def load_data(self):
        HandWriting = sorted(list((self.path/'hand').glob('*')))
        Printed = sorted(list((self.path/'printed').glob('*')))
        
        transform = transforms.Compose([
            transforms.Resize((new_width, new_height)),
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))  # 정규화 추가
        ])

        '''
        각각 Num_Img개 만큼 랜덤으로 가져옴
        이게 싫고 전부 가져오고 싶다면 아래 코드를 쓰면됨 시간이 아주아주 오래 걸릴거임
        나중에 필요하면 아래 코드로 바꿀 예정

        HandWriting_tensor = [transform(Image.open(file)).to(DEVICE) for file in HandWriting]
        Printed_tensor = [transform(Image.open(file)).to(DEVICE) for file in Printed]
        '''
        
        HandWriting_tensor = [transform(Image.open(file)) for file in random.sample(HandWriting, self.num_img)]
        Printed_tensor = [transform(Image.open(file)) for file in random.sample(Printed, self.num_img)]

        labels = [0] * len(HandWriting_tensor) + [1] * len(Printed_tensor)
        data = list(zip(labels, HandWriting_tensor + Printed_tensor))
        random.shuffle(data)
        
        return data
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        label, image = self.data[idx]
        return image, label

# ===========================================================================

# CNN 모델 정의
class CNN(nn.Module):                   # nn.module class 상속
    def __init__(self):
        super(CNN, self).__init__()     # super함수는 CNN class의 부모 class인 nn.Module을 초기화
                                        # 계층(layer) 초기화
        
        self.layer = nn.Sequential(     # 각 모듈을 순차적으로 실행한다.
                                   
            nn.Conv2d(3, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(16, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(0.25),           # 학습하는 동안 입력 텐서의 일부 요소를 확률로 무작위로 0으로 설정
                                        # 신경망을 향상시키기 위한 효과적인 정규화 기법으로, 뉴런의 공적응을 방지하는 방법을 설명한 논문 
                                        # "Improving neural networks by preventing co-adaptation of feature detectors"에서 제시된 기법
            
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(0.25),
            
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(0.25),
            
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(0.25),
            
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(),
        )

        self.fc_layer = nn.Sequential(
            nn.Linear(256 * 12 * 12, 1000),  # 패딩에 의해 수정함
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(1000, 100),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(100, 10),
            nn.ReLU(),
            nn.Linear(10, 2),
        )
        
    def forward(self, x):
        out = self.layer(x)
        out = out.view(out.size(0), -1)  # 배치 크기를 유지하며 평탄화
        out = self.fc_layer(out)
        return out

# ================================Main code==================================


# 데이터 로드
dataset = DL(path, Num_Img)
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# 위에 클래스에서 정의한 모델을 가져옴
# 모델 초기화, DEVICE로 이동
model = CNN().to(DEVICE)

loss_func = nn.CrossEntropyLoss()   # 손실함수를 CrossEntropyLoss를 사용
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # baxkword를 하면 파라미터 값을 조정하는 함수

# 모델 학습
model.train()
for epoch in range(num_epoch):
    total_loss = 0
    model.train()
    
    for images, labels in train_loader:
        images = images.to(DEVICE)
        labels = labels.to(DEVICE)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    val_loss = 0
    correct = 0
    total = 0
    model.eval()
    
    with torch.no_grad():
        for images, labels in val_loader:
            images = images.to(DEVICE)
            labels = labels.to(DEVICE)
            outputs = model(images)
            loss = loss_func(outputs, labels)
            val_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    val_loss /= len(val_loader)
    val_accuracy = 100 * correct / total
    print(f'Epoch [{epoch+1}/{num_epoch}], Train Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')

# 모델 최종 평가
correct = 0
total = 0
model.eval()
with torch.no_grad():
    for images, labels in val_loader:
        images = images.to(DEVICE)
        labels = labels.to(DEVICE)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        
    print(f'Final Accuracy of the model: {100 * correct / total:.2f}%')
